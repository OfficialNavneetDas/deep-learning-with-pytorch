{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a3ff65-35d9-4060-b29f-eab1ad939777",
   "metadata": {},
   "source": [
    "# Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27048a0-ad59-47de-ac9e-e24b717dbf9d",
   "metadata": {},
   "source": [
    "_**dataset and dataLoader** are core abstraction in pytorch that decouple how you define your data from how you efficiently iterate over it_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec13b91-c26d-410c-8e6a-1451fa544016",
   "metadata": {},
   "source": [
    "**Problums it solves**\n",
    "1. No standard interface for data\n",
    "2. No easy way to apply transformations\n",
    "3. shuffling and samplings\n",
    "4. Batch management and parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090782db-cdba-4c58-94d4-4be26d7c28c8",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8aa23-cd74-4847-ab9a-2e92969c71a9",
   "metadata": {},
   "source": [
    "### Dataset Class\n",
    "_The data set class is essentially a blueprint. when you create a custom dataset, you will decide how the data is loaded and returned._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae901800-fef6-45ef-ab43-7162a298c5f6",
   "metadata": {},
   "source": [
    "it defines:  \n",
    "  * ```__init__() ``` Which tells how the data shpuld be loaded **_(from pd.readcsv or by folder)_**\n",
    "  * ```__len__()``` Which returns the total number of samples\n",
    "  * ```__getitem__(index)``` Which return the data (and labels) at the given index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe032477-3cfd-4543-841e-492be81ea815",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "1. At the start of each epoch, the DataLoader (if shuffle=True) shuffles indices (useing a sampler).\n",
    "2. it divides the index into chunk of batch_size\n",
    "3. for each index in the chunk, data samples are fatched from the dataset object\n",
    "4. The samples are then collected and combined into a batch (using collate_fn)\n",
    "5. The batch is returned to the main traning loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d9e44-23dd-49ed-b612-93f640cc04fa",
   "metadata": {},
   "source": [
    "# Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8a58b0-337f-424a-8200-9def0373aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f489c28-501b-4e64-877a-2ab1693d17ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\")\n",
    "df.drop(columns=[\"id\",\"Unnamed: 32\"],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c35133-f6eb-4002-ba48-e0639cdb1865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18c7dfe1-971e-4889-900d-c385e09bcd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
       "         2.75062224,  1.93701461],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
       "        -0.24388967,  0.28118999],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
       "         1.152255  ,  0.20139121],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
       "        -1.10454895, -0.31840916],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
       "         1.91908301,  2.21963528],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
       "        -0.04813821, -0.75120669]], shape=(569, 30))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cb13d94-f4fe-4ee9-b321-d0011a6bd1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e45a4f93-8ac5-4fbf-aa02-17a4c2504817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae4a9aa6-30b9-466b-8b8d-0cfbdf28a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82bb957-1ce6-4a93-a198-8e86783bc4ad",
   "metadata": {},
   "source": [
    "# Working with Dataloader and Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc285b-05f1-42a3-a706-af2936116c80",
   "metadata": {},
   "source": [
    "## Converting array to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17cce4c3-0629-44de-9df1-621147d63a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae5f5e59-3bf9-47ba-9c90-9a817a63a9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([569, 30]),\n",
       " tensor([[ 1.0971, -2.0733,  1.2699,  ...,  2.2961,  2.7506,  1.9370],\n",
       "         [ 1.8298, -0.3536,  1.6860,  ...,  1.0871, -0.2439,  0.2812],\n",
       "         [ 1.5799,  0.4562,  1.5665,  ...,  1.9550,  1.1523,  0.2014],\n",
       "         ...,\n",
       "         [ 0.7023,  2.0456,  0.6727,  ...,  0.4141, -1.1045, -0.3184],\n",
       "         [ 1.8383,  2.3365,  1.9825,  ...,  2.2900,  1.9191,  2.2196],\n",
       "         [-1.8084,  1.2218, -1.8144,  ..., -1.7451, -0.0481, -0.7512]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x #x and y is a pytorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee05982-6625-4d0d-864b-6137a9582ecb",
   "metadata": {},
   "source": [
    "## Creating a custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c8c4eb9-91fe-4c67-a93d-c5f3464e299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1713b7f-9649-472e-951a-538e649af936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "230a0879-b835-4c8b-9758-d0c35d8151da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c8405-e754-46bc-8dcd-fbd983aed823",
   "metadata": {},
   "source": [
    "## Working in DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bcb066-194c-4fd5-a3a4-310742c06106",
   "metadata": {},
   "source": [
    "_format :_ dataloader = **DataLoader(_dataset object_, _batch size_, _shuffle=True/False_)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1485e819-f618-4fd7-8e3c-ddb9a42ff45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x21c897ca5d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef1a4f1b-ce95-4f4d-9c3f-6cfa7fc78337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8172, -1.0494, -0.8481,  ..., -1.4912, -0.1387, -0.5412],\n",
      "        [-0.9052, -0.1628, -0.8888,  ..., -0.5441, -1.0512, -0.3672],\n",
      "        [-0.7149, -0.7609, -0.6800,  ..., -0.0625, -0.1840, -0.5362],\n",
      "        ...,\n",
      "        [-0.9848, -0.9633, -1.0083,  ..., -1.7451, -0.3086, -1.2361],\n",
      "        [-0.3826, -0.6515, -0.4366,  ..., -0.8494, -0.8376, -1.0998],\n",
      "        [ 1.5515, -0.2652,  1.5953,  ...,  1.6764,  1.2008,  0.4591]])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.6042,  2.0805, -0.6261,  ..., -0.6615, -0.7341, -0.1112],\n",
      "        [-1.2466, -1.7033, -1.2657,  ..., -1.7451,  0.3304, -0.1350],\n",
      "        [-0.4508, -0.6911, -0.4415,  ..., -0.4644,  0.4113, -0.4747],\n",
      "        ...,\n",
      "        [ 2.6648,  1.1590,  2.6004,  ...,  1.4358, -0.4979, -0.3639],\n",
      "        [-0.7973,  1.8129, -0.8324,  ..., -1.4279, -0.0837, -0.7246],\n",
      "        [ 0.7165,  0.4864,  0.7427,  ...,  1.4449,  1.1523,  0.6480]])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.8768, -0.5724, -0.8670,  ..., -0.6136,  0.1573, -0.2846],\n",
      "        [-1.2455, -0.0395, -1.2373,  ..., -1.0463,  0.4776, -0.2137],\n",
      "        [ 0.9011, -0.5142,  0.8663,  ...,  1.0825,  0.3838, -0.1560],\n",
      "        ...,\n",
      "        [-0.3571, -0.7167, -0.3950,  ..., -0.8650,  1.1377, -0.7385],\n",
      "        [-0.0418,  0.0769, -0.0350,  ...,  1.0368,  0.4501,  1.1944],\n",
      "        [-0.9592, -1.0052, -0.9766,  ..., -1.2254, -0.9719, -0.9008]])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.2665, -0.2768, -1.2731,  ..., -1.3644,  0.2528, -0.2879],\n",
      "        [-0.1015, -1.4008, -0.1610,  ..., -0.8616, -0.1258, -0.8870],\n",
      "        [ 0.0462, -0.5747, -0.0687,  ..., -1.2376, -0.7163, -1.2605],\n",
      "        ...,\n",
      "        [ 0.1655,  0.5353,  0.1475,  ...,  1.0475,  1.2898,  1.4106],\n",
      "        [-1.2074,  0.0257, -1.1541,  ..., -0.2606, -0.4510,  0.0529],\n",
      "        [-0.8030, -0.2559, -0.7430,  ...,  0.1095,  0.6588,  2.5355]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for batch_features, batch_labels in dataloader:\n",
    "    if i==4:break\n",
    "    print(batch_features)\n",
    "    print(batch_labels)\n",
    "    print(\"-\"*50)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4248f4e-29cc-4585-9a58-efc0987d1aee",
   "metadata": {},
   "source": [
    "# Components of the data loading pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a9ad8-194c-4d15-bfd2-a91ed6d56ed5",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f7be6-135d-4478-958c-156eb7c5e14b",
   "metadata": {},
   "source": [
    "The data transformation is done inside the custom dataset class  \n",
    "```python\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        all the transformations are done here before return statement\n",
    "        '''\n",
    "        return self.features[index], self.labels[index]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa71861-5ed7-4469-b316-1ef3b52466b2",
   "metadata": {},
   "source": [
    "## Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ac7d3-4240-4bed-b1c7-0aa7ffb97f4e",
   "metadata": {},
   "source": [
    "### Type of Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665e030-73d3-4e8b-a488-be1b19041b77",
   "metadata": {},
   "source": [
    "1. SequentialSampler\n",
    "2. RandomSampler\n",
    "3. CustomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd988fd-c097-4b18-9503-f3c8868469b8",
   "metadata": {},
   "source": [
    "## Collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f415be-d0fe-43db-a27b-159a0fd9ec9f",
   "metadata": {},
   "source": [
    "* The Collate_fn in pytorch is a function that specifies how to combine a list of samples from a dataset into a list of sample from the dataset into a single batch\n",
    "* By default, the dataLoader uses a simple batch collection mechanisum, but collate_fn allow you to customize that how the data should be processed and batched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe629a-7ea8-4d0c-b790-63f142b18d6c",
   "metadata": {},
   "source": [
    "## dataLoader Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90940ecc-c870-4b2f-8be9-529d01f7347a",
   "metadata": {},
   "source": [
    "|s.no|components|Working|\n",
    "|----|----------|-------|\n",
    "|1|dataset (mendatory)|1. dataset from which the dataLoader will pull data|\n",
    "|||2. Must be sub class of torch.utils.data.Dataset that implements ```__getitem__``` and ```__len__```|\n",
    "||||\n",
    "|2|batch_size|1. How many samples per batch to load|\n",
    "|||2. default is 1.|\n",
    "|||3. Larger batch size can speed up traning on GPU but required more memory|\n",
    "||||\n",
    "|3|shuffle|1 how the shuffle the dataset|\n",
    "||||\n",
    "|4|num_workes|1. The number of worker processes used to load data in parallel|\n",
    "|||2. setting num_workers>0 can speedup the data loading by useing multiple CPU cores, especially if I/O is a bottleneck|\n",
    "||||\n",
    "|5|pin_memory|1. if True the dataloader will copy tensors into pinned (page-locked) memory before returning them.|\n",
    "|||2. this can improve transfur speed over all traning time|\n",
    "||||\n",
    "|6|drop_last|1. if True, the dataloader will drop the last batch if the last batch is not divided by the batch size|\n",
    "|||2. usefull when exect batch size is required|\n",
    "||||\n",
    "|7|collate_fn| a collabe that process a list of sample into a batch|\n",
    "|||custom collate_fn can handle veriable length sequence, perform custom batching, logic and handle complex data stracture|\n",
    "||||\n",
    "|8|sampler|1. sampler define the strategy for drowing samples|\n",
    "|||2. batch_sampler workes at batch level, controlling how batches are formed|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044a3a6-12a3-4609-b1a6-207537fbb616",
   "metadata": {},
   "source": [
    "# Improving our code for Mini-batch gradient descent (MBGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ebb329e-823b-4c24-a7d9-f23efc3dd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e9881-9e79-4ff7-9bcb-f9e9661b0623",
   "metadata": {},
   "source": [
    "## 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51d517de-9801-4de1-9183-67f1fda4773a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9e3e5d6-9e4a-47fa-a27f-a4690ec54f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef100407-ef59-42af-80c7-30c43cf47d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"id\",\"Unnamed: 32\"],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d09dc-7094-4265-aea0-d888d1dc0661",
   "metadata": {},
   "source": [
    "## 2. Basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "481db752-1d2c-4c3d-9c47-df19193fa10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of xtrain = (455, 30)\n",
      "size of xtest = (114, 30)\n",
      "size of ytrain = (455,)\n",
      "size of ytest = (114,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(df.iloc[:,1:], df.iloc[:,0], test_size=0.2)\n",
    "print(f\"size of xtrain = {xtrain.shape}\")\n",
    "print(f\"size of xtest = {xtest.shape}\")\n",
    "print(f\"size of ytrain = {ytrain.shape}\")\n",
    "print(f\"size of ytest = {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1d226-a49f-42c7-9851-bf0f9dc596ff",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe405a1e-c532-418e-9ce0-60e0e87a0b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95981435,  4.70220918,  0.8952502 , ...,  1.38525468,\n",
       "        -0.08463945,  0.05430031],\n",
       "       [ 0.45152639,  0.26590046,  0.38404019, ...,  0.59038292,\n",
       "         0.85328096,  0.1277591 ],\n",
       "       [-0.82496951, -1.35240509, -0.79760918, ..., -0.43901385,\n",
       "        -1.29076655, -0.87726599],\n",
       "       ...,\n",
       "       [-1.14553749, -1.00395491, -1.15168497, ..., -1.35228365,\n",
       "         1.04600434, -0.20470995],\n",
       "       [-0.78164952, -0.88468672, -0.79509503, ..., -0.45945341,\n",
       "        -0.36890642, -0.88760463],\n",
       "       [-0.68634552,  0.56757881, -0.72553695, ..., -1.18028854,\n",
       "        -0.75917125, -0.99752075]], shape=(455, 30))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(xtrain)\n",
    "x_test = scaler.transform(xtest)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b65be-b9dd-4797-9547-e2879b2dd422",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bacfbfc5-0196-4cc6-9d84-42a316205892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "y_train = encoder.fit_transform(ytrain)\n",
    "y_test = encoder.transform(ytest)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc287e1-117a-436c-b99e-28baf718ef3c",
   "metadata": {},
   "source": [
    "## 3. Numpy array to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "598ed764-1636-4dae-a92c-f6f47e2e2c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tensor = torch.from_numpy(x_train).float()\n",
    "xtest_tensor = torch.from_numpy(x_test).float()\n",
    "ytrain_tensor = torch.from_numpy(y_train).float()\n",
    "ytest_tensor = torch.from_numpy(y_test).float()\n",
    "xtrain_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "261f36e0-2581-4b6e-9a8d-8bedf427ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57cc7b5b-af20-4ddc-a2d6-0095b47067a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(xtrain_tensor, ytrain_tensor)\n",
    "test_dataset = CustomDataset(xtest_tensor, ytest_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0260483-bf50-41c3-9345-f80ff073b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a952bc-93c3-4a09-b49c-8b4917a4a052",
   "metadata": {},
   "source": [
    "## 4. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85c21ddd-a557-4b72-8cec-5e4ed265853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MySampleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)\n",
    "        y_pred = self.sigmoid(z)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b9b59-a6be-4ca1-b8f2-1a0c165d2bdf",
   "metadata": {},
   "source": [
    "## 5. Important peramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23b65ee2-9fe3-421a-b0f7-24e9c8a6f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a77bb30-b5af-4e77-85b6-71f0bccd7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create model object\n",
    "model = MySampleNN(xtrain_tensor.shape[1])\n",
    "\n",
    "# define loss function\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477dc4c-113b-4b53-b88b-eb6994cb9ce2",
   "metadata": {},
   "source": [
    "## 6. Traning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb0f91f2-1842-4009-b3b1-96ec3334ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, Loss:0.06697898358106613\n",
      "epoch:2, Loss:0.005849621258676052\n",
      "epoch:3, Loss:0.026851404458284378\n",
      "epoch:4, Loss:0.0021070712246000767\n",
      "epoch:5, Loss:0.0011778130428865552\n",
      "epoch:6, Loss:0.0034802102018147707\n",
      "epoch:7, Loss:0.005072867032140493\n",
      "epoch:8, Loss:0.06353352963924408\n",
      "epoch:9, Loss:0.007249873131513596\n",
      "epoch:10, Loss:0.11506259441375732\n",
      "epoch:11, Loss:0.053134653717279434\n",
      "epoch:12, Loss:0.015455037355422974\n",
      "epoch:13, Loss:0.0035428237169981003\n",
      "epoch:14, Loss:0.0011248314986005425\n",
      "epoch:15, Loss:0.004652294795960188\n",
      "epoch:16, Loss:0.003202262567356229\n",
      "epoch:17, Loss:0.05506148561835289\n",
      "epoch:18, Loss:0.035806674510240555\n"
     ]
    }
   ],
   "source": [
    "# define loop\n",
    "for epoch in range(epoch):\n",
    "    batch_no=0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_no += 1\n",
    "        # print(f\" starting batch:{batch_no}\", end='')\n",
    "\n",
    "        # forword pass\n",
    "        y_pred = model(batch_features)\n",
    "        # print(\"..\",end='')\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_function(y_pred, batch_labels.view(-1,1))\n",
    "        # print(\"..\",end='')\n",
    "\n",
    "        # clear gradient\n",
    "        optimizer.zero_grad()\n",
    "        # print(\"..\",end='')\n",
    "\n",
    "        # backword pass\n",
    "        loss.backward()\n",
    "        # print(\"..\",end='')\n",
    "\n",
    "        # peramaters update\n",
    "        optimizer.step()\n",
    "        # print(\"completed !\")\n",
    "        \n",
    "    print(f\"epoch:{epoch+1}, Loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "265eb331-75f3-4e51-9d8d-7f7f76ee704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9627\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using test loader\n",
    "model.eval() #set the model to eval mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # forword pass\n",
    "        y_pred = model.forward(batch_features)\n",
    "        y_pred = (y_pred>0.5).float()\n",
    "\n",
    "        # accuracy of current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# calculate over all accuracy\n",
    "total_accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "print(f\"Accuracy: {total_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
